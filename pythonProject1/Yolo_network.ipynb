{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-07T09:24:48.235572Z",
     "start_time": "2025-11-07T09:24:42.433018Z"
    }
   },
   "source": [
    "# pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from typing import List, Any, Union"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilisateur\\OneDrive - Groupe ESAIP\\Bureau\\Cetic_code\\pythonProject1\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T09:24:51.361926Z",
     "start_time": "2025-11-07T09:24:48.250940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"parquet\", data_files=\"data/mmimdb_merged.parquet\", split=\"train\")"
   ],
   "id": "d2592a45ce5f1f9b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T09:28:32.528778Z",
     "start_time": "2025-11-07T09:28:32.522849Z"
    }
   },
   "cell_type": "code",
   "source": "print(ds[0])",
   "id": "ab2b771519bb6319",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'user', 'content': 'Given the movie poster and the corresponding plot of the movie, choose the appropriategenres from the following comma separated genres: drama, comedy, romance, thriller, crime, action, adventure,horror, documentry, mystery, sci-fi, fantasy, family, biography, war, history, music, animation, musical,western, sport, short, film-noir.\\nPlot: Mild mannered businessman Anthony Wongs life is shattered when his pregnant wife is run over by a busy taxi driver. This and another incident with a sleazy cab driver causes Wong to go on a mission to kill bad taxi drivers.\\nNote that a movie can belong to more than one genres,provide all the suitable genres separated by commas. Answer:'}, {'role': 'assistant', 'content': 'Crime, Drama, Thriller'}], 'images': [<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=265x475 at 0x2462FFF2FD0>]}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T14:50:08.033167Z",
     "start_time": "2025-11-04T14:50:08.027784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n"
   ],
   "id": "c966317cce071470",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T14:50:10.289157Z",
     "start_time": "2025-11-04T14:50:10.284898Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "566b6371ece1c456",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:45:07.060964Z",
     "start_time": "2025-11-04T14:56:44.519869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1) Score de chaleur (HSV via PIL, pas d'OpenCV) ---\n",
    "def warmth_score_hsv_pil(img: Image.Image) -> float:\n",
    "    \"\"\"\n",
    "    Score ~ fraction de pixels 'chauds' (rouge/orange/jaune) pondérée par la saturation,\n",
    "    en ignorant les pixels très sombres et très peu saturés.\n",
    "    Retourne un float entre 0 et 1.\n",
    "    \"\"\"\n",
    "    if img.mode != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    hsv = img.convert(\"HSV\")\n",
    "    arr = np.array(hsv).astype(np.float32)  # H,S,V in [0..255]\n",
    "    H = arr[..., 0] * (360.0 / 255.0)\n",
    "    S = arr[..., 1] / 255.0\n",
    "    V = arr[..., 2] / 255.0\n",
    "\n",
    "    # Masques anti-bruit\n",
    "    valid = (V > 0.15) & (S > 0.15)\n",
    "\n",
    "    # Teintes chaudes: [0°,75°] U [300°,360°]\n",
    "    warm = ((H >= 0) & (H <= 75)) | ((H >= 300) & (H <= 360))\n",
    "\n",
    "    weights = S * valid\n",
    "    warm_w = (warm * weights).sum()\n",
    "    total_w = weights.sum()\n",
    "    return float(warm_w / total_w) if total_w > 0 else 0.0\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def ensure_pil(x):\n",
    "    \"\"\"\n",
    "    Retourne un objet PIL.Image.Image à partir de ce que renvoie la colonne 'images'.\n",
    "    - Si c'est déjà une Image -> la retourne\n",
    "    - Si c'est une liste [Image] -> retourne le premier élément\n",
    "    - Sinon -> None\n",
    "    \"\"\"\n",
    "    if isinstance(x, Image.Image):\n",
    "        return x\n",
    "    if isinstance(x, list) and len(x) > 0 and isinstance(x[0], Image.Image):\n",
    "        return x[0]\n",
    "    return None\n",
    "def extract_genres(msg: Any) -> List[str]:\n",
    "    \"\"\"\n",
    "    Tente plusieurs formats possibles:\n",
    "    - dict avec 'genres' (liste de str)\n",
    "    - dict avec 'genres' (string \"A|B|C\")\n",
    "    - string \"A|B|C\" ou \"A, B, C\"\n",
    "    \"\"\"\n",
    "    if isinstance(msg, dict):\n",
    "        # Essaye plusieurs clés plausibles\n",
    "        for k in [\"genres\", \"genre\", \"labels\", \"tags\"]:\n",
    "            if k in msg:\n",
    "                val = msg[k]\n",
    "                if isinstance(val, list):\n",
    "                    return [str(v).strip() for v in val if str(v).strip()]\n",
    "                if isinstance(val, str):\n",
    "                    sep = \"|\" if \"|\" in val else \",\"\n",
    "                    return [v.strip() for v in val.split(sep) if v.strip()]\n",
    "    if isinstance(msg, str):\n",
    "        sep = \"|\" if \"|\" in msg else \",\"\n",
    "        return [v.strip() for v in msg.split(sep) if v.strip()]\n",
    "    return []\n",
    "\n",
    "# --- 2) Charger le dataset HF ---\n",
    "ds = load_dataset(\"parquet\", data_files=\"data/mmimdb_merged.parquet\", split=\"train\")\n",
    "\n",
    "# --- 3) Calculer chaleur + genres (par batch pour la vitesse) ---\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def compute_batch(batch):\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    from typing import Any, List\n",
    "#<<<<----------------------------<>>>>>>>>>>>>>>>>\n",
    "    # --- 1) Score de chaleur (défini localement pour les workers) ---\n",
    "    def warmth_score_hsv_pil(img: Image.Image) -> float:\n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "        hsv = img.convert(\"HSV\")\n",
    "        arr = np.array(hsv).astype(np.float32)  # H,S,V in [0..255]\n",
    "        H = arr[..., 0] * (360.0 / 255.0)\n",
    "        S = arr[..., 1] / 255.0\n",
    "        V = arr[..., 2] / 255.0\n",
    "        valid = (V > 0.15) & (S > 0.15)\n",
    "        warm = ((H >= 0) & (H <= 75)) | ((H >= 300) & (H <= 360))\n",
    "        weights = S * valid\n",
    "        warm_w = (warm * weights).sum()\n",
    "        total_w = weights.sum()\n",
    "        return float(warm_w / total_w) if total_w > 0 else 0.0\n",
    "\n",
    "    # --- 2) Extracteur de genres (défini localement aussi) ---\n",
    "    def extract_genres(msg: Any) -> List[str]:\n",
    "        if isinstance(msg, dict):\n",
    "            for k in [\"genres\", \"genre\", \"labels\", \"tags\"]:\n",
    "                if k in msg:\n",
    "                    val = msg[k]\n",
    "                    if isinstance(val, list):\n",
    "                        return [str(v).strip() for v in val if str(v).strip()]\n",
    "                    if isinstance(val, str):\n",
    "                        sep = \"|\" if \"|\" in val else \",\"\n",
    "                        return [v.strip() for v in val.split(sep) if v.strip()]\n",
    "        if isinstance(msg, str):\n",
    "            sep = \"|\" if \"|\" in msg else \",\"\n",
    "            return [v.strip() for v in msg.split(sep) if v.strip()]\n",
    "        return []\n",
    "\n",
    "    imgs = batch[\"images\"]\n",
    "    msgs = batch[\"messages\"]\n",
    "    warmths, genres = [], []\n",
    "\n",
    "    for im, msg in zip(imgs, msgs):\n",
    "        if isinstance(im, Image.Image):\n",
    "            pil = im\n",
    "        elif isinstance(im, list) and len(im) > 0 and isinstance(im[0], Image.Image):\n",
    "            pil = im[0]\n",
    "        else:\n",
    "            pil = None\n",
    "\n",
    "        score = np.nan if pil is None else warmth_score_hsv_pil(pil)\n",
    "        warmths.append(score)\n",
    "        genres.append(extract_genres(msg))\n",
    "\n",
    "    return {\"warmth\": warmths, \"genres\": genres}\n",
    "\n",
    "\n",
    "#<<<<----------------------------<>>>>>>>>>>>>>>>>\n",
    "\n",
    "\n",
    "ds = ds.map(compute_batch, batched=True, batch_size=64, num_proc=1)\n",
    "\n",
    "\n",
    "# --- 4) Agrégation par genre ---\n",
    "# Convertir en pandas pour exploiter explode / groupby (15k lignes = OK en RAM)\n",
    "df = ds.to_pandas()\n",
    "\n",
    "# Supprimer NaN chaleu\n",
    "df = df.dropna(subset=[\"warmth\"])\n",
    "\n",
    "# Exploser la liste de genres en lignes\n",
    "df_exploded = df.explode(\"genres\")\n",
    "df_exploded[\"genres\"] = df_exploded[\"genres\"].astype(str).str.strip()\n",
    "df_exploded = df_exploded[df_exploded[\"genres\"] != \"\"]\n",
    "\n",
    "agg = (df_exploded\n",
    "       .groupby(\"genres\", as_index=False)\n",
    "       .agg(mean_warmth=(\"warmth\", \"mean\"),\n",
    "            median_warmth=(\"warmth\", \"median\"),\n",
    "            n=(\"warmth\", \"count\"))\n",
    "       .sort_values(\"mean_warmth\", ascending=False))\n",
    "\n",
    "print(agg.head(10))\n",
    "\n",
    "# --- 5) Visualisation : \"carte\" simple = barres triées ---\n",
    "plt.figure(figsize=(9, 10))\n",
    "plt.barh(agg[\"genres\"], agg[\"mean_warmth\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Score de chaleur moyen (0–1)\")\n",
    "plt.title(\"Chaleur moyenne des couleurs par genre (affiches)\")\n",
    "for i, v in enumerate(agg[\"mean_warmth\"]):\n",
    "    plt.text(v + 0.005, i, f\"{v:.2f}\", va=\"center\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f48b48e30b0638cd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=1): 100%|██████████| 15552/15552 [46:52<00:00,  5.53 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  genres  mean_warmth  median_warmth      n\n",
      "0    nan     0.698017       0.826156  15552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x1000 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T13:39:17.876637Z",
     "start_time": "2025-11-04T13:39:17.307226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(ds[0]['images'])\n",
    "img = ds[85][\"images\"]\n",
    "model = YOLO(\"yolo11s.pt\")\n",
    "print(model.names)\n",
    "\n",
    "# 2) Nombre de classes\n",
    "print(len(model.names))  # 80 ≈ COCO (généraliste). Petit nombre = souvent spécialisé.\n",
    "\n",
    "# 3) Type de tâche (détection/seg/pose/obb)\n",
    "print(model.task)  # 'detect', 'segment', 'pose', etc.\n",
    "\n",
    "# Inférence sur une image\n",
    "results = model(img)  # renvoie boîtes, classes, scores\n",
    "results[0].show()\n",
    "# évaluer sur COCO (val2017)\n",
    "model(\"image.jpg\")  # prédire\n"
   ],
   "id": "cc1dae34598fd4da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=265x475 at 0x21D3095DBA0>]\n",
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "80\n",
      "detect\n",
      "\n",
      "0: 640x448 1 person, 55.0ms\n",
      "Speed: 3.9ms preprocess, 55.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "image.jpg does not exist",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 16\u001B[39m\n\u001B[32m     14\u001B[39m results[\u001B[32m0\u001B[39m].show()  \n\u001B[32m     15\u001B[39m    \u001B[38;5;66;03m# évaluer sur COCO (val2017)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mimage.jpg\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m              \u001B[38;5;66;03m# prédire\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive - Groupe ESAIP\\Bureau\\Cetic_code\\pythonProject1\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:182\u001B[39m, in \u001B[36mModel.__call__\u001B[39m\u001B[34m(self, source, stream, **kwargs)\u001B[39m\n\u001B[32m    154\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\n\u001B[32m    155\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    156\u001B[39m     source: \u001B[38;5;28mstr\u001B[39m | Path | \u001B[38;5;28mint\u001B[39m | Image.Image | \u001B[38;5;28mlist\u001B[39m | \u001B[38;5;28mtuple\u001B[39m | np.ndarray | torch.Tensor = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    157\u001B[39m     stream: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    158\u001B[39m     **kwargs: Any,\n\u001B[32m    159\u001B[39m ) -> \u001B[38;5;28mlist\u001B[39m:\n\u001B[32m    160\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Alias for the predict method, enabling the model instance to be callable for predictions.\u001B[39;00m\n\u001B[32m    161\u001B[39m \n\u001B[32m    162\u001B[39m \u001B[33;03m    This method simplifies the process of making predictions by allowing the model instance to be called directly\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    180\u001B[39m \u001B[33;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001B[39;00m\n\u001B[32m    181\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive - Groupe ESAIP\\Bureau\\Cetic_code\\pythonProject1\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:540\u001B[39m, in \u001B[36mModel.predict\u001B[39m\u001B[34m(self, source, stream, predictor, **kwargs)\u001B[39m\n\u001B[32m    538\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m prompts \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.predictor, \u001B[33m\"\u001B[39m\u001B[33mset_prompts\u001B[39m\u001B[33m\"\u001B[39m):  \u001B[38;5;66;03m# for SAM-type models\u001B[39;00m\n\u001B[32m    539\u001B[39m     \u001B[38;5;28mself\u001B[39m.predictor.set_prompts(prompts)\n\u001B[32m--> \u001B[39m\u001B[32m540\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.predictor.predict_cli(source=source) \u001B[38;5;28;01mif\u001B[39;00m is_cli \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpredictor\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m=\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive - Groupe ESAIP\\Bureau\\Cetic_code\\pythonProject1\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:225\u001B[39m, in \u001B[36mBasePredictor.__call__\u001B[39m\u001B[34m(self, source, model, stream, *args, **kwargs)\u001B[39m\n\u001B[32m    223\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.stream_inference(source, model, *args, **kwargs)\n\u001B[32m    224\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m225\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstream_inference\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive - Groupe ESAIP\\Bureau\\Cetic_code\\pythonProject1\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001B[39m, in \u001B[36m_wrap_generator.<locals>.generator_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     34\u001B[39m     \u001B[38;5;66;03m# Issuing `None` to a generator fires it up\u001B[39;00m\n\u001B[32m     35\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m         response = \u001B[43mgen\u001B[49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     38\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m     39\u001B[39m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     40\u001B[39m             \u001B[38;5;66;03m# Forward the response to our caller and get its next request\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive - Groupe ESAIP\\Bureau\\Cetic_code\\pythonProject1\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:299\u001B[39m, in \u001B[36mBasePredictor.stream_inference\u001B[39m\u001B[34m(self, source, model, *args, **kwargs)\u001B[39m\n\u001B[32m    295\u001B[39m     \u001B[38;5;28mself\u001B[39m.setup_model(model)\n\u001B[32m    297\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:  \u001B[38;5;66;03m# for thread-safe inference\u001B[39;00m\n\u001B[32m    298\u001B[39m     \u001B[38;5;66;03m# Setup source every time predict is called\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m299\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msetup_source\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msource\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    301\u001B[39m     \u001B[38;5;66;03m# Check if save_dir/ label file exists\u001B[39;00m\n\u001B[32m    302\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.save \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.save_txt:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive - Groupe ESAIP\\Bureau\\Cetic_code\\pythonProject1\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:255\u001B[39m, in \u001B[36mBasePredictor.setup_source\u001B[39m\u001B[34m(self, source)\u001B[39m\n\u001B[32m    248\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Set up source and inference mode.\u001B[39;00m\n\u001B[32m    249\u001B[39m \n\u001B[32m    250\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m    251\u001B[39m \u001B[33;03m    source (str | Path | list[str] | list[Path] | list[np.ndarray] | np.ndarray | torch.Tensor): Source for\u001B[39;00m\n\u001B[32m    252\u001B[39m \u001B[33;03m        inference.\u001B[39;00m\n\u001B[32m    253\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    254\u001B[39m \u001B[38;5;28mself\u001B[39m.imgsz = check_imgsz(\u001B[38;5;28mself\u001B[39m.args.imgsz, stride=\u001B[38;5;28mself\u001B[39m.model.stride, min_dim=\u001B[32m2\u001B[39m)  \u001B[38;5;66;03m# check image size\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m255\u001B[39m \u001B[38;5;28mself\u001B[39m.dataset = \u001B[43mload_inference_source\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    256\u001B[39m \u001B[43m    \u001B[49m\u001B[43msource\u001B[49m\u001B[43m=\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    257\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    258\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvid_stride\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvid_stride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    259\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstream_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    260\u001B[39m \u001B[43m    \u001B[49m\u001B[43mchannels\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mch\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    261\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    262\u001B[39m \u001B[38;5;28mself\u001B[39m.source_type = \u001B[38;5;28mself\u001B[39m.dataset.source_type\n\u001B[32m    263\u001B[39m long_sequence = (\n\u001B[32m    264\u001B[39m     \u001B[38;5;28mself\u001B[39m.source_type.stream\n\u001B[32m    265\u001B[39m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.source_type.screenshot\n\u001B[32m    266\u001B[39m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m.dataset) > \u001B[32m1000\u001B[39m  \u001B[38;5;66;03m# many images\u001B[39;00m\n\u001B[32m    267\u001B[39m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.dataset, \u001B[33m\"\u001B[39m\u001B[33mvideo_flag\u001B[39m\u001B[33m\"\u001B[39m, [\u001B[38;5;28;01mFalse\u001B[39;00m]))\n\u001B[32m    268\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive - Groupe ESAIP\\Bureau\\Cetic_code\\pythonProject1\\.venv\\Lib\\site-packages\\ultralytics\\data\\build.py:417\u001B[39m, in \u001B[36mload_inference_source\u001B[39m\u001B[34m(source, batch, vid_stride, buffer, channels)\u001B[39m\n\u001B[32m    415\u001B[39m     dataset = LoadPilAndNumpy(source, channels=channels)\n\u001B[32m    416\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m417\u001B[39m     dataset = \u001B[43mLoadImagesAndVideos\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvid_stride\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvid_stride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchannels\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchannels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    419\u001B[39m \u001B[38;5;66;03m# Attach source types to the dataset\u001B[39;00m\n\u001B[32m    420\u001B[39m \u001B[38;5;28msetattr\u001B[39m(dataset, \u001B[33m\"\u001B[39m\u001B[33msource_type\u001B[39m\u001B[33m\"\u001B[39m, source_type)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive - Groupe ESAIP\\Bureau\\Cetic_code\\pythonProject1\\.venv\\Lib\\site-packages\\ultralytics\\data\\loaders.py:369\u001B[39m, in \u001B[36mLoadImagesAndVideos.__init__\u001B[39m\u001B[34m(self, path, batch, vid_stride, channels)\u001B[39m\n\u001B[32m    367\u001B[39m         files.append(\u001B[38;5;28mstr\u001B[39m((parent / p).absolute()))  \u001B[38;5;66;03m# files (relative to *.txt file parent)\u001B[39;00m\n\u001B[32m    368\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m369\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mp\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m does not exist\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    371\u001B[39m \u001B[38;5;66;03m# Define files as images or videos\u001B[39;00m\n\u001B[32m    372\u001B[39m images, videos = [], []\n",
      "\u001B[31mFileNotFoundError\u001B[39m: image.jpg does not exist"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:28:27.358693Z",
     "start_time": "2025-11-04T09:28:27.231894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img = ds[1540][\"images\"]\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "id": "808df679ec09dbf7",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m img = ds[\u001B[32m1540\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mimages\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mimg\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshow\u001B[49m()\n",
      "\u001B[31mAttributeError\u001B[39m: 'list' object has no attribute 'show'"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:14:18.747959Z",
     "start_time": "2025-11-04T08:14:18.533144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Charger un modèle pré-entraîné (détection)\n",
    "model = YOLO(\"yolov8n.pt\")  # n = nano (rapide et léger)\n",
    "\n",
    "# 1) Liste des classes apprises\n",
    "print(model.names)  # dict: id -> nom de classe\n",
    "\n",
    "# 2) Nombre de classes\n",
    "print(len(model.names))  # 80 ≈ COCO (généraliste). Petit nombre = souvent spécialisé.\n",
    "\n",
    "# 3) Type de tâche (détection/seg/pose/obb)\n",
    "print(model.task)  # 'detect', 'segment', 'pose', etc.\n",
    "\n",
    "# Inférence sur une image\n",
    "results = model(img)  # renvoie boîtes, classes, scores\n",
    "results[0].show()  # affiche l’image annotée\n",
    "\n",
    "# Fine-tuning sur vos données (format COCO ou dossier/images + labels .txt)\n",
    "# model.train(data=\"data.yaml\", epochs=50, imgsz=640)\n"
   ],
   "id": "a62a9be66d9d00bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "80\n",
      "detect\n",
      "\n",
      "0: 640x448 7 persons, 26.9ms\n",
      "Speed: 2.8ms preprocess, 26.9ms inference, 11.2ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T14:22:02.993366Z",
     "start_time": "2025-11-04T14:22:02.946615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rgb_to_hsl(R, G, B):\n",
    "    r, g, b = R / 255.0, G / 255.0, B / 255.0\n",
    "    M, m = max(r, g, b), min(r, g, b)\n",
    "    L = (M + m) / 2.0\n",
    "    if M == m:\n",
    "        return 0.0, 0.0, L\n",
    "    d = M - m\n",
    "    S = d / (1 - abs(2 * L - 1))\n",
    "    if M == r:\n",
    "        H = ((g - b) / d) % 6\n",
    "    elif M == g:\n",
    "        H = (b - r) / d + 2\n",
    "    else:\n",
    "        H = (r - g) / d + 4\n",
    "    H *= 60.0\n",
    "    return H, S, L\n",
    "\n",
    "\n",
    "img2 = ds[1540][\"images\"]\n"
   ],
   "id": "bc21071f120808ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=317x475 at 0x1C7A68D5A90>]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T13:47:40.269081Z",
     "start_time": "2025-11-04T13:46:30.841023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from diffusers import AutoPipelineForImage2Image\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "\n",
    "pipeline = AutoPipelineForImage2Image.from_pretrained(\n",
    "    \"kandinsky-community/kandinsky-2-2-decoder\", torch_dtype=torch.float16, use_safetensors=True\n",
    ")\n",
    "pipeline.enable_model_cpu_offload()\n",
    "# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\n",
    "pipeline.enable_xformers_memory_efficient_attention()"
   ],
   "id": "de43d89cb1e6ebb6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "init_image = load_image(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png\")"
   ],
   "id": "2af9db0348f8d319"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = \"cat biker, moto, sons of anarchy, detailed, scary, adorable\"\n",
    "image = pipeline(prompt, image=init_image).images[0]\n",
    "make_image_grid([init_image, image], rows=1, cols=2)"
   ],
   "id": "884bf7978bae44b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
