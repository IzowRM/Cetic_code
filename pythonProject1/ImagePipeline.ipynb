{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-30T07:37:55.006224Z",
     "start_time": "2025-10-30T07:37:55.003164Z"
    }
   },
   "source": [
    "# !pip install -q transformers \n",
    "# !pip install -q peft\n",
    "# !pip install -q evaluate\n",
    "# !pip install -q wandb"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T07:38:05.601268Z",
     "start_time": "2025-10-30T07:37:55.127407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from datasets import load_dataset\n",
    "# ds = load_dataset(\"parquet\", data_files=\"data/mmimdb_merged.parquet\", split=\"train\") "
   ],
   "id": "47a0e5999461890c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilisateur\\OneDrive - Groupe ESAIP\\Bureau\\Cetic_code\\pythonProject1\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T07:38:06.210308Z",
     "start_time": "2025-10-30T07:38:06.207502Z"
    }
   },
   "cell_type": "code",
   "source": "# !python.exe -m pip install --upgrade pip",
   "id": "38e3d998a500a275",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T07:38:06.319232Z",
     "start_time": "2025-10-30T07:38:06.218400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# img = ds[0][\"images\"]          # -> objet PIL.Image.Image\n",
    "# img"
   ],
   "id": "d4d4a5c5bb69d9a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=265x475>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T07:38:06.477500Z",
     "start_time": "2025-10-30T07:38:06.462201Z"
    }
   },
   "cell_type": "code",
   "source": "# len(ds[0][\"images\"])",
   "id": "ac765af41d606759",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T07:38:07.821434Z",
     "start_time": "2025-10-30T07:38:06.624713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from PIL import Image\n",
    "# Image.MAX_IMAGE_PIXELS = 175_000_000\n",
    "# ds_single = ds.map(\n",
    "#     lambda ex: {\"image\": ex[\"images\"][0]},\n",
    "#     remove_columns=[\"images\"]\n",
    "# )\n",
    "# print(ds_single.features)\n"
   ],
   "id": "43718c491d4b14ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': List({'role': Value('string'), 'content': Value('string')}), 'image': Image(mode=None, decode=True)}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T07:38:07.855969Z",
     "start_time": "2025-10-30T07:38:07.837281Z"
    }
   },
   "cell_type": "code",
   "source": "# print(ds_single[302]['messages'])",
   "id": "10850ecdebaa5782",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': \"Given the movie poster and the corresponding plot of the movie, choose the appropriategenres from the following comma separated genres: drama, comedy, romance, thriller, crime, action, adventure,horror, documentry, mystery, sci-fi, fantasy, family, biography, war, history, music, animation, musical,western, sport, short, film-noir.\\nPlot: In the early 1600's, Countess Elizabeth Bathory slaughtered more than 600 young women, believing if she bathed in the blood of virgins that she would stay young and beautiful forever. Still alive today, she's found a perfect hunting ground for her 'botox' as an abstinence educator in conservative America, and the young ladies of San Griento High are poised to be her next victims. But will her unholy ritual finally be stopped by Leah Ratliff, a feminist blogger and ambitious reporter for the school paper?\\nNote that a movie can belong to more than one genres,provide all the suitable genres separated by commas. Answer:\"}, {'role': 'assistant', 'content': 'Comedy, Horror'}]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# ds_single[302]['image']",
   "id": "27c8e07829ba39e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T08:30:11.940890Z",
     "start_time": "2025-10-30T08:03:09.061987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def flatten_text_only(example):\n",
    "# \n",
    "#     msgs = example.get(\"messages\", []) or []\n",
    "#     assistant_msgs = [m.get(\"content\", \"\") for m in msgs if m.get(\"role\") == \"assistant\"]\n",
    "# \n",
    "#     answer = assistant_msgs[-1] if assistant_msgs else \"\"\n",
    "# \n",
    "#     return {\n",
    "#         \"answer\": answer,\n",
    "#         \"images\": example['image']\n",
    "#     }\n",
    "# ds_flat = ds_single.map(flatten_text_only, remove_columns=ds_single.column_names)"
   ],
   "id": "9c4825a912a864b5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 15552/15552 [27:02<00:00,  9.58 examples/s]  \n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T14:52:03.283315Z",
     "start_time": "2025-10-30T14:49:15.350059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_from_disk\n",
    "import numpy as np\n",
    "\n",
    "ds_flat = load_from_disk(r\"data/ds_flat\")\n",
    "\n",
    "# 1) Vocabulaire des genres (unique & trié)\n",
    "all_genres = set()\n",
    "for ans in ds_flat['answer']:\n",
    "    if ans is None:\n",
    "        continue\n",
    "    for g in ans.split(','):\n",
    "        g = g.strip()\n",
    "        if g:\n",
    "            all_genres.add(g)\n",
    "\n",
    "genres = sorted(all_genres)  # doit faire 23\n",
    "print(\"Nb de genres:\", len(genres))\n",
    "print(genres)\n",
    "\n",
    "assert len(genres) == 26, \"Le nombre de genres n'est pas 26. Vérifie tes données.\"\n",
    "\n",
    "genre2id = {g:i for i, g in enumerate(genres)}\n",
    "\n",
    "# 2) Fonction de mapping -> labels_idx + labels (multi-hot)\n",
    "def encode_labels(example):\n",
    "    # Parse propre de la réponse\n",
    "    raw = example.get(\"answer\") or \"\"\n",
    "    items = [g.strip() for g in raw.split(\",\") if g.strip()]\n",
    "\n",
    "    # indices (ignore genre inconnu, si jamais)\n",
    "    idxs = [genre2id[g] for g in items if g in genre2id]\n",
    "\n",
    "    # multi-hot\n",
    "    y = np.zeros(len(genres), dtype=np.float32)\n",
    "    if idxs:\n",
    "        y[idxs] = 1.0\n",
    "\n",
    "    example[\"labels_idx\"] = idxs                   \n",
    "    example[\"labels\"] = y                          \n",
    "    return example\n",
    "\n",
    "ds_flat = ds_flat.map(encode_labels, desc=\"Ajout des colonnes labels\")\n",
    "\n",
    "# (Optionnel) sauvegarder le vocabulaire pour l'inférence\n",
    "import json, os\n",
    "os.makedirs(\"data/label_vocab\", exist_ok=True)\n",
    "with open(\"data/label_vocab/genres.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"genres\": genres}, f, ensure_ascii=False, indent=2)"
   ],
   "id": "792871f0782ad14c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb de genres: 26\n",
      "['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ajout des colonnes labels: 100%|██████████| 15552/15552 [02:45<00:00, 94.21 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biography, Comedy, Drama, History\n",
      "[3, 4, 7, 11]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 53\u001B[39m\n\u001B[32m     51\u001B[39m \u001B[38;5;28mprint\u001B[39m(ds_flat[\u001B[32m301\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33manswer\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     52\u001B[39m \u001B[38;5;28mprint\u001B[39m(ds_flat[\u001B[32m301\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mlabels_idx\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[43mds_flat\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m301\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlabels\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdtype\u001B[49m, ds_flat[\u001B[32m301\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mlabels\u001B[39m\u001B[33m\"\u001B[39m].shape)\n",
      "\u001B[31mAttributeError\u001B[39m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T14:56:52.002059Z",
     "start_time": "2025-10-30T14:56:51.989696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Vérif rapide\n",
    "print(ds_flat[301][\"answer\"])\n",
    "print(ds_flat[301][\"labels_idx\"])\n",
    "arr = np.array(ds_flat[301][\"labels\"], dtype=np.float32)\n",
    "print(arr.dtype, arr.shape)\n"
   ],
   "id": "b6d19b527b56840c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biography, Comedy, Drama, History\n",
      "[3, 4, 7, 11]\n",
      "float32 (26,)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T15:47:49.929047Z",
     "start_time": "2025-10-30T15:47:42.817484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset, load_from_disk\n",
    "\n",
    "# # Sauver\n",
    "# ds_flat.save_to_disk(r\"data/ds_flat_labeled\")\n",
    "\n",
    "# Recharger\n",
    "# Recharger depuis le dossier sauvegardé\n",
    "ds_flat = load_from_disk(\"data/ds_flat_labeled\")"
   ],
   "id": "f335cdcdd2c106e9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilisateur\\OneDrive - Groupe ESAIP\\Bureau\\Cetic_code\\pythonProject1\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T15:50:02.343414Z",
     "start_time": "2025-10-30T15:50:02.185447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys, torch\n",
    "print(sys.executable)\n",
    "print(torch.__version__, torch.version.cuda)\n",
    "print(torch.cuda.is_available(), torch.cuda.get_device_name(0))"
   ],
   "id": "67489a0e909103f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilisateur\\OneDrive - Groupe ESAIP\\Bureau\\Cetic_code\\pythonProject1\\.venv\\Scripts\\python.exe\n",
      "2.6.0+cu124 12.4\n",
      "True NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T15:47:54.333761Z",
     "start_time": "2025-10-30T15:47:54.319264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds_flat.set_format(type=\"torch\", columns=[\"labels\"])  # + \"pixel_values\" quand tes images seront prêtes\n",
    "batch = ds_flat[:8]\n",
    "print(batch[\"labels\"].dtype, batch[\"labels\"].shape)   # torch.float32, (8, 26)"
   ],
   "id": "d6e5506b8163a44b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.Size([8, 26])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-30T16:10:19.128325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalisation\n",
    "from datasets import load_from_disk, Image as HFImage\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "ds_flat = ds_flat.cast_column(\"images\", HFImage(decode=True))  # <-- important\n",
    "\n",
    "# Normalisation (ImageNet par défaut ; adapte si tu as tes propres stats)\n",
    "MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "def pil_to_np_rgb_noresize(img: Image.Image):\n",
    "    if img.mode != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    arr = np.asarray(img).astype(np.float32) / 255.0      # HWC\n",
    "    arr = (arr - MEAN) / STD\n",
    "    arr = np.transpose(arr, (2, 0, 1))                    # CHW\n",
    "    return arr\n",
    "\n",
    "def pick_first_image(value):\n",
    "    \"\"\"Accepte PIL.Image, liste de PIL, ou None.\"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, list) and len(value) > 0:\n",
    "        return value[0]\n",
    "    return value  # supposé être une PIL.Image\n",
    "\n",
    "def add_pixel_values(example):\n",
    "    img = pick_first_image(example[\"images\"])\n",
    "    if img is None:\n",
    "        example[\"pixel_values\"] = None\n",
    "    else:\n",
    "        example[\"pixel_values\"] = pil_to_np_rgb_noresize(img).astype(np.float32)\n",
    "    return example\n",
    "\n",
    "# 2) Ajouter la colonne sans resize\n",
    "ds_flat = ds_flat.map(add_pixel_values, desc=\"pixel_values sans resize\")\n",
    "\n",
    "# 3) Collate avec padding dynamique (tailles variables) pour PyTorch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def collate_pad(batch):\n",
    "    xs, ys = [], []\n",
    "    for b in batch:\n",
    "        if b[\"pixel_values\"] is None:\n",
    "            continue  # skip si pas d'image\n",
    "        x = torch.from_numpy(b[\"pixel_values\"]) if isinstance(b[\"pixel_values\"], np.ndarray) else b[\"pixel_values\"]\n",
    "        xs.append(x)                    # (C,H,W)\n",
    "        ys.append(b[\"labels\"])\n",
    "    # max H,W du lot\n",
    "    C = xs[0].shape[0]\n",
    "    H = max(x.shape[1] for x in xs)\n",
    "    W = max(x.shape[2] for x in xs)\n",
    "\n",
    "    x_pad = torch.zeros(len(xs), C, H, W, dtype=torch.float32)\n",
    "    mask  = torch.zeros(len(xs), 1, H, W, dtype=torch.bool)\n",
    "    for i, x in enumerate(xs):\n",
    "        c,h,w = x.shape\n",
    "        x_pad[i, :, :h, :w] = x\n",
    "        mask[i, :, :h, :w] = True\n",
    "\n",
    "    y = torch.stack(ys) if isinstance(ys[0], torch.Tensor) else torch.tensor(ys)\n",
    "    return {\"pixel_values\": x_pad, \"labels\": y, \"attention_mask\": mask}\n",
    "\n",
    "loader = DataLoader(ds_flat, batch_size=8, shuffle=True, collate_fn=collate_pad)\n",
    "\n",
    "# test d’un batch\n",
    "batch = next(iter(loader))\n",
    "print(batch[\"pixel_values\"].shape)   # -> [B, 3, Hmax, Wmax]\n",
    "print(batch[\"labels\"].shape)\n",
    "print(batch[\"attention_mask\"].shape) # même Hmax, Wmax\n"
   ],
   "id": "3a36cfa683348f53",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixel_values sans resize:   2%|▏         | 343/15552 [00:06<09:52, 25.67 examples/s] "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CNN part\n",
   "id": "ac9a37b5528d90e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T15:08:39.699389Z",
     "start_time": "2025-10-30T15:08:39.687598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# step1_multilabel_skeleton.py\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np"
   ],
   "id": "a6a9d17298ff4c50",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Architecture Alexnet :\n",
   "id": "85af307f372ab3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T15:08:41.589168Z",
     "start_time": "2025-10-30T15:08:41.575743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,num_labels):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 100, 3,padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(3, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(100, 32, 3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3,padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 128, 3,padding=1)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(128, 80, 3,padding=1)\n",
    "        self.bn7   = nn.BatchNorm2d(80)\n",
    "        self.pool2 = nn.MaxPool2d(3, 2)\n",
    "        \n",
    "        #Applatie la matatrice pour le model \n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        \n",
    "        #Une couche de model \n",
    "        self.fc1 = nn.LazyLinear(80)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(80)\n",
    "        \n",
    "        #pour tester \n",
    "        self.out = nn.Linear(80, num_labels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool2(F.relu(self.bn7(self.conv7(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.bn_fc1(self.fc1(x)))\n",
    "        logits = self.out(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n"
   ],
   "id": "52b548bcc1c2d0a3",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T15:08:44.304622Z",
     "start_time": "2025-10-30T15:08:44.286143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(ds_flat, batch_size=32, shuffle=True)"
   ],
   "id": "83b487d4e0a4749a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T15:08:46.939394Z",
     "start_time": "2025-10-30T15:08:46.695454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch, torch.nn as nn\n",
    "\n",
    "num_labels = 26\n",
    "model = Net(num_labels)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for batch in train_loader:\n",
    "    images = batch[\"pixel_values\"]          # (B,3,H,W)\n",
    "    targets = batch[\"labels\"].float()       # (B,26)\n",
    "    logits = model(images)                  # (B,26)\n",
    "    loss = criterion(logits, targets)\n",
    "    optimizer.zero_grad(); loss.backward(); optimizer.step()\n"
   ],
   "id": "5078c780334baf9",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pixel_values'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      6\u001B[39m optimizer = torch.optim.Adam(model.parameters(), lr=\u001B[32m1e-3\u001B[39m)\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m     images = \u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpixel_values\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m          \u001B[38;5;66;03m# (B,3,H,W)\u001B[39;00m\n\u001B[32m     10\u001B[39m     targets = batch[\u001B[33m\"\u001B[39m\u001B[33mlabels\u001B[39m\u001B[33m\"\u001B[39m].float()       \u001B[38;5;66;03m# (B,26)\u001B[39;00m\n\u001B[32m     11\u001B[39m     logits = model(images)                  \u001B[38;5;66;03m# (B,26)\u001B[39;00m\n",
      "\u001B[31mKeyError\u001B[39m: 'pixel_values'"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "nromalisation à revoir ",
   "id": "a074792b8fbeca76"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
